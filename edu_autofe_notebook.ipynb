{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class AutoFE:\n",
    "    \n",
    "    def __init__(self, max_results=10):\n",
    "        self.max_results = max_results\n",
    "        self.results = []\n",
    "        \n",
    "    def _evaluate_feature(self, X_base, new_feature, y):\n",
    "        scaler = StandardScaler()\n",
    "        model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "        \n",
    "        # Concatenate new feature with existing ones\n",
    "        X_with_new = pd.concat([X_base, new_feature], axis=1)\n",
    "        \n",
    "        # Scale and run cross validation\n",
    "        X_scaled = scaler.fit_transform(X_with_new)\n",
    "        scores = cross_val_score(model, X_scaled, y, cv=5, scoring='accuracy')\n",
    "        \n",
    "        return scores.mean(), scores.std()\n",
    "    \n",
    "    def _generate_candidates(self, X):\n",
    "        candidates = []\n",
    "        \n",
    "        # Single column transformations only for now\n",
    "        transforms = {\n",
    "            'log': lambda x: np.log(x + 1),\n",
    "            'sqrt': lambda x: np.sqrt(np.abs(x)),\n",
    "            'square': lambda x: x ** 2,\n",
    "        }\n",
    "        \n",
    "        for col in X.columns:\n",
    "            for name, func in transforms.items():\n",
    "                try:\n",
    "                    transformed = func(X[col])\n",
    "                    \n",
    "                    if pd.isna(transformed).any() or np.isinf(transformed).any():\n",
    "                        continue\n",
    "                    \n",
    "                    feature_name = f'{name}({col})'\n",
    "                    feature_series = pd.Series(transformed, index=X.index, name=feature_name)\n",
    "                    \n",
    "                    candidates.append((feature_name, feature_series))\n",
    "                except:\n",
    "                    continue\n",
    "        \n",
    "        return candidates\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        print(\"Calculating baseline...\")\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "        \n",
    "        model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "        scores = cross_val_score(model, X_scaled, y, cv=5, scoring='accuracy')\n",
    "        \n",
    "        baseline_score = scores.mean()\n",
    "        \n",
    "        print(f\"Baseline Accuracy: {baseline_score:.4f}\")\n",
    "        print(\"Testing transformations...\")\n",
    "        \n",
    "        candidates = self._generate_candidates(X)\n",
    "        \n",
    "        for feature_name, feature_series in candidates:\n",
    "            try:\n",
    "                new_feature_df = pd.DataFrame({feature_name: feature_series})\n",
    "                score, std = self._evaluate_feature(X, new_feature_df, y)\n",
    "                improvement = score - baseline_score\n",
    "                \n",
    "                if improvement > 0:\n",
    "                    self.results.append({\n",
    "                        'feature': feature_name,\n",
    "                        'score': score,\n",
    "                        'improvement': improvement\n",
    "                    })\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        self.results.sort(key=lambda x: x['improvement'], reverse=True)\n",
    "        results_df = pd.DataFrame(self.results[:self.max_results])\n",
    "        \n",
    "        if len(results_df) > 0:\n",
    "            print(f\"\\nTop {len(results_df)} improvements:\")\n",
    "            for i, row in results_df.iterrows():\n",
    "                print(f\"  {row['feature']}: {row['score']:.4f} (+{row['improvement']:.4f})\")\n",
    "        \n",
    "        return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\n",
    "X = df.drop(columns=[\"Survived\"])\n",
    "y = df[\"Survived\"]\n",
    "\n",
    "# Preprocessing\n",
    "X = X.drop(columns=['PassengerId', 'Name', 'Cabin', 'Ticket'])\n",
    "X = pd.get_dummies(X, drop_first=True, dtype=int)\n",
    "X = X.fillna(X.median())\n",
    "\n",
    "# Test\n",
    "autofe = AutoFE(max_results=5)\n",
    "results = autofe.fit(X, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "class EduAutoFE:\n",
    "    \n",
    "    def __init__(self, max_results=10):\n",
    "        self.max_results = max_results\n",
    "        self.results = []\n",
    "    \n",
    "    def _validate_input(self, X, y):\n",
    "        \n",
    "        # X needs to be a dataframe\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            raise TypeError(\n",
    "                \"Error: X must be a pandas DataFrame\\n\"\n",
    "                \"Fix: X = pd.DataFrame(X)\"\n",
    "            )\n",
    "        \n",
    "        # Y needs to be a series\n",
    "        if not isinstance(y, pd.Series):\n",
    "            raise TypeError(\n",
    "                \"Error: y must be a pandas Series\\n\"\n",
    "                \"Fix: y = df['target_column']\"\n",
    "            )\n",
    "        \n",
    "        # Check for too many columns\n",
    "        if len(X.columns) > 50:\n",
    "            raise ValueError(\n",
    "                f\"Error: Too many columns ({len(X.columns)})\\n\"\n",
    "                f\"This usually means you encoded high-cardinality columns.\\n\"\n",
    "                f\"Drop them before encoding.\"\n",
    "            )\n",
    "        \n",
    "        # Check for ID columns\n",
    "        id_patterns = [\"id\", \"index\", \"key\"]\n",
    "        for col in X.columns:\n",
    "            col_lower = col.lower()\n",
    "            if any(pattern in col_lower for pattern in id_patterns):\n",
    "                if X[col].dtype in [np.int64, np.float64]:\n",
    "                    uniqueness = X[col].nunique() / len(X)\n",
    "                    if uniqueness > 0.95:\n",
    "                        raise ValueError(f\"Error: {col} looks like an ID column. Drop it.\")\n",
    "        \n",
    "        # Check for text columns\n",
    "        cat_cols = X.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "        if cat_cols:\n",
    "            raise ValueError(\n",
    "                f\"Error: Found text columns: {cat_cols}\\n\"\n",
    "                f\"Fix: X = pd.get_dummies(X, drop_first=True, dtype=int)\"\n",
    "            )\n",
    "        \n",
    "        # Check for missing values\n",
    "        if X.isnull().any().any():\n",
    "            cols_with_missing = X.columns[X.isnull().any()].tolist()\n",
    "            raise ValueError(\n",
    "                f\"Error: Missing values in: {cols_with_missing}\\n\"\n",
    "                f\"Fix: X = X.fillna(X.median())\"\n",
    "            )\n",
    "\n",
    "        # Check for missing values\n",
    "        if y.isnull().any():\n",
    "            raise ValueError(\n",
    "                f\"Error: Missing values in y\\n\"\n",
    "                f\"Fix: y = y.fillna(y.median())\"\n",
    "            )\n",
    "        \n",
    "        return X, y\n",
    "        \n",
    "    def _detect_task_type(self, y):\n",
    "        n_unique = y.nunique()\n",
    "\n",
    "        # If there are only two different values, it is a Binary Classification problem\n",
    "        if n_unique == 2:\n",
    "            print(f\"Detected: Binary Classification ({n_unique} classes)\")\n",
    "            print(f\"   Model: Logistic Regression\\n\")\n",
    "            return \"classification\"\n",
    "        else:\n",
    "            print(f\"Detected: Regression ({n_unique} unique values)\")\n",
    "            print(f\"   Model: Linear Regression\\n\")\n",
    "            return \"regression\"\n",
    "    \n",
    "    def _evaluate_feature(self, X_base, new_feature, y):\n",
    "        scaler = StandardScaler()\n",
    "        \n",
    "        if self.task_type == \"regression\":\n",
    "            model = LinearRegression()\n",
    "            scoring = \"r2\"\n",
    "        else:\n",
    "            model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "            scoring = \"accuracy\"\n",
    "        \n",
    "        X_with_new = pd.concat([X_base, new_feature], axis=1)\n",
    "        X_scaled = scaler.fit_transform(X_with_new)\n",
    "        scores = cross_val_score(model, X_scaled, y, cv=5, scoring=scoring)\n",
    "        \n",
    "        return scores.mean(), scores.std()\n",
    "    \n",
    "    def _generate_candidates(self, X):\n",
    "        candidates = []\n",
    "        \n",
    "        # Single column transformations with descriptions\n",
    "        transforms = {\n",
    "            \"log\": (lambda x: np.log(x + 1), \"Log of {col} - reduces skewness\"),\n",
    "            \"sqrt\": (lambda x: np.sqrt(np.abs(x)), \"Square root of {col} - mild skew reduction\"),\n",
    "            \"square\": (lambda x: x ** 2, \"Square of {col} - captures quadratic relationships\"),\n",
    "            \"cube\": (lambda x: x ** 3, \"Cube of {col} - strong nonlinear relationships\"),\n",
    "            \"inverse\": (lambda x: 1 / (x + 1e-5), \"Inverse of {col} - inverse relationships\"),\n",
    "        }\n",
    "\n",
    "        # Generate single column transformations\n",
    "        for col in X.columns:\n",
    "            for name, (func, desc_template) in transforms.items():\n",
    "                try:\n",
    "                    transformed = func(X[col])\n",
    "                    \n",
    "                    if pd.isna(transformed).any() or np.isinf(transformed).any():\n",
    "                        continue\n",
    "                    \n",
    "                    feature_name = f\"{name}({col})\"\n",
    "                    feature_series = pd.Series(transformed, index=X.index, name=feature_name)\n",
    "                    description = desc_template.format(col=col)\n",
    "                    \n",
    "                    candidates.append((feature_name, feature_series, description))\n",
    "                except:\n",
    "                    continue\n",
    "        \n",
    "        # Pairwise operations with descriptions\n",
    "        operations = {\n",
    "            \"multiply\": (lambda a, b: a * b, \"Product of {col1} and {col2} - interaction effect\"),\n",
    "            \"divide\": (lambda a, b: a / (b + 1e-5), \"Ratio of {col1} to {col2}\"),\n",
    "        }\n",
    "        \n",
    "        continuous_cols = [col for col in X.columns if X[col].nunique() > 2]\n",
    "\n",
    "        # Generate pairwise transformations\n",
    "        for i, col1 in enumerate(continuous_cols):\n",
    "            for col2 in continuous_cols[i+1:]:\n",
    "                for op_name, (func, desc_template) in operations.items():\n",
    "                    try:\n",
    "                        transformed = func(X[col1], X[col2])\n",
    "                        \n",
    "                        if pd.isna(transformed).any() or np.isinf(transformed).any():\n",
    "                            continue\n",
    "                        \n",
    "                        feature_name = f\"{col1} {op_name} {col2}\"\n",
    "                        feature_series = pd.Series(transformed, index=X.index, name=feature_name)\n",
    "                        description = desc_template.format(col1=col1, col2=col2)\n",
    "                        \n",
    "                        candidates.append((feature_name, feature_series, description))\n",
    "                    except:\n",
    "                        continue\n",
    "        \n",
    "        return candidates\n",
    "    \n",
    "    def _print_results(self, df, baseline_score, baseline_std, metric):\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(f\"{\"RESULTS\":^60}\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"\\nBaseline {metric}: {baseline_score:.4f} +/- {baseline_std:.4f}\")\n",
    "        \n",
    "        if len(df) > 0:\n",
    "            best = df.iloc[0][\"improvement\"]\n",
    "            print(f\"Best improvement: +{best:.4f}\")\n",
    "        \n",
    "        print(f\"\\nTop {len(df)} Transformations:\")\n",
    "        print(\"-\"*60)\n",
    "        \n",
    "        for i, row in df.iterrows():\n",
    "            print(f\"\\n{i+1}. {row[\"feature\"]}\")\n",
    "            print(f\"   {metric}: {row[\"score\"]:.4f} +/- {row[\"std\"]:.4f} (+{row[\"improvement\"]:.4f})\")\n",
    "            print(f\"   {row[\"description\"]}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Validate input\n",
    "        X, y = self._validate_input(X, y)\n",
    "\n",
    "        # Set task type\n",
    "        self.task_type = self._detect_task_type(y)\n",
    "\n",
    "        # Calculate baseline\n",
    "        print(\"Calculating baseline performance...\")\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "        # Detect task type and choose model and metric accordingly\n",
    "        if self.task_type == \"regression\":\n",
    "            model = LinearRegression()\n",
    "            scores = cross_val_score(model, X_scaled, y, cv=5, scoring=\"r2\")\n",
    "            metric = \"R2\"\n",
    "        else:\n",
    "            model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "            scores = cross_val_score(model, X_scaled, y, cv=5, scoring=\"accuracy\")\n",
    "            metric = \"Accuracy\"\n",
    "        \n",
    "        baseline_score = scores.mean()\n",
    "        baseline_std = scores.std()\n",
    "\n",
    "        # Print the baseline score\n",
    "        print(f\"Baseline {metric}: {baseline_score:.4f} +/- {baseline_std:.4f}\")\n",
    "        print(\"Generating candidates...\")\n",
    "\n",
    "        # Generate and test candidates\n",
    "        candidates = self._generate_candidates(X)\n",
    "        \n",
    "        print(f\"Testing {len(candidates)} candidates...\")\n",
    "        \n",
    "        for feature_name, feature_series, description in candidates:\n",
    "            try:\n",
    "                new_feature_df = pd.DataFrame({feature_name: feature_series})\n",
    "                score, std = self._evaluate_feature(X, new_feature_df, y)\n",
    "                improvement = score - baseline_score\n",
    "                \n",
    "                if improvement > 0:\n",
    "                    self.results.append({\n",
    "                        \"feature\": feature_name,\n",
    "                        \"score\": score,\n",
    "                        \"std\": std,\n",
    "                        \"improvement\": improvement,\n",
    "                        \"description\": description\n",
    "                    })\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        # Check if there were no features that improved the performance\n",
    "        if len(self.results) == 0:\n",
    "            print(\"No improvements found over baseline.\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        # Sort results by improvement\n",
    "        self.results.sort(key=lambda x: x[\"improvement\"], reverse=True)\n",
    "        results_df = pd.DataFrame(self.results[:self.max_results])\n",
    "\n",
    "        # Print the results\n",
    "        self._print_results(results_df, baseline_score, baseline_std, metric)\n",
    "        \n",
    "        return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Pclass                                               Name  \\\n",
       "0              1       3                            Braund, Mr. Owen Harris   \n",
       "1              2       1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "2              3       3                             Heikkinen, Miss. Laina   \n",
       "3              4       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "4              5       3                           Allen, Mr. William Henry   \n",
       "..           ...     ...                                                ...   \n",
       "886          887       2                              Montvila, Rev. Juozas   \n",
       "887          888       1                       Graham, Miss. Margaret Edith   \n",
       "888          889       3           Johnston, Miss. Catherine Helen \"Carrie\"   \n",
       "889          890       1                              Behr, Mr. Karl Howell   \n",
       "890          891       3                                Dooley, Mr. Patrick   \n",
       "\n",
       "        Sex   Age  SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
       "0      male  22.0      1      0         A/5 21171   7.2500   NaN        S  \n",
       "1    female  38.0      1      0          PC 17599  71.2833   C85        C  \n",
       "2    female  26.0      0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3    female  35.0      1      0            113803  53.1000  C123        S  \n",
       "4      male  35.0      0      0            373450   8.0500   NaN        S  \n",
       "..      ...   ...    ...    ...               ...      ...   ...      ...  \n",
       "886    male  27.0      0      0            211536  13.0000   NaN        S  \n",
       "887  female  19.0      0      0            112053  30.0000   B42        S  \n",
       "888  female   NaN      1      2        W./C. 6607  23.4500   NaN        S  \n",
       "889    male  26.0      0      0            111369  30.0000  C148        C  \n",
       "890    male  32.0      0      0            370376   7.7500   NaN        Q  \n",
       "\n",
       "[891 rows x 11 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "X = df.drop(columns=[\"Survived\"])\n",
    "y = df[\"Survived\"]\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected: Binary Classification (2 classes)\n",
      "   Model: Logistic Regression\n",
      "\n",
      "Calculating baseline performance...\n",
      "Baseline Accuracy: 0.7857 +/- 0.0184\n",
      "Generating candidates...\n",
      "Testing 60 candidates...\n",
      "\n",
      "============================================================\n",
      "                          RESULTS                           \n",
      "============================================================\n",
      "\n",
      "Baseline Accuracy: 0.7857 +/- 0.0184\n",
      "Best improvement: +0.0224\n",
      "\n",
      "Top 10 Transformations:\n",
      "------------------------------------------------------------\n",
      "\n",
      "1. log(Age)\n",
      "   Accuracy: 0.8081 +/- 0.0237 (+0.0224)\n",
      "   Log of Age - reduces skewness\n",
      "\n",
      "2. sqrt(Age)\n",
      "   Accuracy: 0.8036 +/- 0.0210 (+0.0179)\n",
      "   Square root of Age - mild skew reduction\n",
      "\n",
      "3. inverse(Age)\n",
      "   Accuracy: 0.8002 +/- 0.0246 (+0.0146)\n",
      "   Inverse of Age - inverse relationships\n",
      "\n",
      "4. Pclass divide Age\n",
      "   Accuracy: 0.7980 +/- 0.0253 (+0.0123)\n",
      "   Ratio of Pclass to Age\n",
      "\n",
      "5. square(Age)\n",
      "   Accuracy: 0.7969 +/- 0.0211 (+0.0112)\n",
      "   Square of Age - captures quadratic relationships\n",
      "\n",
      "6. SibSp divide Parch\n",
      "   Accuracy: 0.7957 +/- 0.0180 (+0.0101)\n",
      "   Ratio of SibSp to Parch\n",
      "\n",
      "7. Pclass multiply SibSp\n",
      "   Accuracy: 0.7946 +/- 0.0218 (+0.0090)\n",
      "   Product of Pclass and SibSp - interaction effect\n",
      "\n",
      "8. inverse(SibSp)\n",
      "   Accuracy: 0.7935 +/- 0.0171 (+0.0078)\n",
      "   Inverse of SibSp - inverse relationships\n",
      "\n",
      "9. cube(Age)\n",
      "   Accuracy: 0.7924 +/- 0.0205 (+0.0067)\n",
      "   Cube of Age - strong nonlinear relationships\n",
      "\n",
      "10. Pclass multiply Parch\n",
      "   Accuracy: 0.7924 +/- 0.0199 (+0.0067)\n",
      "   Product of Pclass and Parch - interaction effect\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing\n",
    "X = X.drop(columns=[\"PassengerId\"])\n",
    "X = X.drop(columns=[\"Name\"])\n",
    "X = X.drop(columns=[\"Cabin\"])\n",
    "X = X.drop(columns=[\"Ticket\"])\n",
    "\n",
    "X = pd.get_dummies(X, drop_first=True, dtype=int)\n",
    "X = X.fillna(X.median())\n",
    "y = y.fillna(y.median())\n",
    "\n",
    "# Run\n",
    "model = EduAutoFE(max_results=10)\n",
    "results = model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "class EduAutoFE:\n",
    "    \n",
    "    def __init__(self, max_results=10):\n",
    "        self.max_results = max_results\n",
    "        self.results = []\n",
    "    \n",
    "    def _validate_input(self, X, y):\n",
    "        # Basic checks\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            raise TypeError(\"X must be a pandas DataFrame\")\n",
    "        \n",
    "        if not isinstance(y, pd.Series):\n",
    "            raise TypeError(\"y must be a pandas Series\")\n",
    "        \n",
    "        # Check for non-numeric columns\n",
    "        cat_cols = X.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "        if cat_cols:\n",
    "            raise ValueError(f\"Found non-numeric columns: {cat_cols}. Encode them first.\")\n",
    "        \n",
    "        # Check for missing values\n",
    "        if X.isnull().any().any():\n",
    "            raise ValueError(\"X contains missing values. Fill them first.\")\n",
    "        \n",
    "        return X, y\n",
    "        \n",
    "    def _detect_task_type(self, y):\n",
    "        n_unique = y.nunique()\n",
    "\n",
    "        # If there are only two different values, it is a Binary Classification problem\n",
    "        if n_unique == 2:\n",
    "            print(f\"Detected: Binary Classification\")\n",
    "            return \"classification\"\n",
    "        else:\n",
    "            print(f\"Detected: Regression\")\n",
    "            return \"regression\"\n",
    "    \n",
    "    def _evaluate_feature(self, X_base, new_feature, y):\n",
    "        scaler = StandardScaler()\n",
    "        \n",
    "        if self.task_type == \"regression\":\n",
    "            model = LinearRegression()\n",
    "            scoring = \"r2\"\n",
    "        else:\n",
    "            model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "            scoring = \"accuracy\"\n",
    "        \n",
    "        X_with_new = pd.concat([X_base, new_feature], axis=1)\n",
    "        X_scaled = scaler.fit_transform(X_with_new)\n",
    "        scores = cross_val_score(model, X_scaled, y, cv=5, scoring=scoring)\n",
    "        \n",
    "        return scores.mean(), scores.std()\n",
    "    \n",
    "    def _generate_candidates(self, X):\n",
    "        candidates = []\n",
    "        \n",
    "        # Single column transformations\n",
    "        transforms = {\n",
    "            \"log\": lambda x: np.log(x + 1),\n",
    "            \"sqrt\": lambda x: np.sqrt(np.abs(x)),\n",
    "            \"square\": lambda x: x ** 2,\n",
    "            \"cube\": lambda x: x ** 3,\n",
    "            \"inverse\": lambda x: 1 / (x + 1e-5),\n",
    "        }\n",
    "\n",
    "        # Generate single column transformations\n",
    "        for col in X.columns:\n",
    "            for name, func in transforms.items():\n",
    "                try:\n",
    "                    transformed = func(X[col])\n",
    "                    \n",
    "                    if pd.isna(transformed).any() or np.isinf(transformed).any():\n",
    "                        continue\n",
    "                    \n",
    "                    feature_name = f\"{name}({col})\"\n",
    "                    feature_series = pd.Series(transformed, index=X.index, name=feature_name)\n",
    "                    \n",
    "                    candidates.append((feature_name, feature_series))\n",
    "                except:\n",
    "                    continue\n",
    "        \n",
    "        # Pairwise operations\n",
    "        operations = {\n",
    "            \"multiply\": lambda a, b: a * b,\n",
    "            \"divide\": lambda a, b: a / (b + 1e-5),\n",
    "        }\n",
    "        \n",
    "        continuous_cols = [col for col in X.columns if X[col].nunique() > 2]\n",
    "\n",
    "        # Generate pairwise transformations\n",
    "        for i, col1 in enumerate(continuous_cols):\n",
    "            for col2 in continuous_cols[i+1:]:\n",
    "                for op_name, func in operations.items():\n",
    "                    try:\n",
    "                        transformed = func(X[col1], X[col2])\n",
    "                        \n",
    "                        if pd.isna(transformed).any() or np.isinf(transformed).any():\n",
    "                            continue\n",
    "                        \n",
    "                        feature_name = f\"{col1} {op_name} {col2}\"\n",
    "                        feature_series = pd.Series(transformed, index=X.index, name=feature_name)\n",
    "                        \n",
    "                        candidates.append((feature_name, feature_series))\n",
    "                    except:\n",
    "                        continue\n",
    "        \n",
    "        return candidates\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # Validate input\n",
    "        X, y = self._validate_input(X, y)\n",
    "\n",
    "        # Set task type\n",
    "        self.task_type = self._detect_task_type(y)\n",
    "\n",
    "\n",
    "        # Calculate baseline\n",
    "        print(\"Calculating baseline...\")\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "        \n",
    "        if self.task_type == \"regression\":\n",
    "            model = LinearRegression()\n",
    "            scores = cross_val_score(model, X_scaled, y, cv=5, scoring=\"r2\")\n",
    "            metric = \"R2\"\n",
    "        else:\n",
    "            model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "            scores = cross_val_score(model, X_scaled, y, cv=5, scoring=\"accuracy\")\n",
    "            metric = \"Accuracy\"\n",
    "        \n",
    "        baseline_score = scores.mean()\n",
    "        baseline_std = scores.std()\n",
    "        \n",
    "        print(f\"Baseline {metric}: {baseline_score:.4f} +/- {baseline_std:.4f}\")\n",
    "        print(\"Generating candidates...\")\n",
    "\n",
    "        \n",
    "        # Generate and test candidates\n",
    "        candidates = self._generate_candidates(X)\n",
    "        \n",
    "        print(f\"Testing {len(candidates)} candidates...\")\n",
    "        \n",
    "        for feature_name, feature_series in candidates:\n",
    "            try:\n",
    "                new_feature_df = pd.DataFrame({feature_name: feature_series})\n",
    "                score, std = self._evaluate_feature(X, new_feature_df, y)\n",
    "                improvement = score - baseline_score\n",
    "                \n",
    "                if improvement > 0:\n",
    "                    self.results.append({\n",
    "                        \"feature\": feature_name,\n",
    "                        \"score\": score,\n",
    "                        \"std\": std,\n",
    "                        \"improvement\": improvement\n",
    "                    })\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        # Check if there were no features that improved the performance\n",
    "        if len(self.results) == 0:\n",
    "            print(\"No improvements found.\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        self.results.sort(key=lambda x: x[\"improvement\"], reverse=True)\n",
    "        results_df = pd.DataFrame(self.results[:self.max_results])\n",
    "\n",
    "        # Print the results\n",
    "        print(f\"\\nTop {len(results_df)} improvements:\")\n",
    "        for i, row in results_df.iterrows():\n",
    "            print(f\"  {i+1}. {row[\"feature\"]}\")\n",
    "            print(f\"     {metric}: {row[\"score\"]:.4f} +/- {row[\"std\"]:.4f} (+{row[\"improvement\"]:.4f})\")\n",
    "        \n",
    "        return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected: Binary Classification\n",
      "Calculating baseline...\n",
      "Baseline Accuracy: 0.7857 +/- 0.0184\n",
      "Generating candidates...\n",
      "Testing 60 candidates...\n",
      "\n",
      "Top 10 improvements:\n",
      "  1. log(Age)\n",
      "     Accuracy: 0.8081 +/- 0.0237 (+0.0224)\n",
      "  2. sqrt(Age)\n",
      "     Accuracy: 0.8036 +/- 0.0210 (+0.0179)\n",
      "  3. inverse(Age)\n",
      "     Accuracy: 0.8002 +/- 0.0246 (+0.0146)\n",
      "  4. Pclass divide Age\n",
      "     Accuracy: 0.7980 +/- 0.0253 (+0.0123)\n",
      "  5. square(Age)\n",
      "     Accuracy: 0.7969 +/- 0.0211 (+0.0112)\n",
      "  6. SibSp divide Parch\n",
      "     Accuracy: 0.7957 +/- 0.0180 (+0.0101)\n",
      "  7. Pclass multiply SibSp\n",
      "     Accuracy: 0.7946 +/- 0.0218 (+0.0090)\n",
      "  8. inverse(SibSp)\n",
      "     Accuracy: 0.7935 +/- 0.0171 (+0.0078)\n",
      "  9. cube(Age)\n",
      "     Accuracy: 0.7924 +/- 0.0205 (+0.0067)\n",
      "  10. Pclass multiply Parch\n",
      "     Accuracy: 0.7924 +/- 0.0199 (+0.0067)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "X = df.drop(columns=[\"Survived\"])\n",
    "y = df[\"Survived\"]\n",
    "\n",
    "# Preprocessing\n",
    "X = X.drop(columns=[\"PassengerId\", \"Name\", \"Cabin\", \"Ticket\"])\n",
    "X = pd.get_dummies(X, drop_first=True, dtype=int)\n",
    "X = X.fillna(X.median())\n",
    "\n",
    "# Test\n",
    "autofe = EduAutoFE(max_results=10)\n",
    "results = autofe.fit(X, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
